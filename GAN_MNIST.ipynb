{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1KD3ZgLs80vY",
        "Mvjjan17qHjq"
      ]
    },
    "coursera": {
      "schema_names": [
        "GANSC1-1A"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfkorNJrnmNO"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from tqdm.auto import tqdm\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "torch.manual_seed(0)\n",
        "\n",
        "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28)):\n",
        "\n",
        "    image_unflat = image_tensor.detach().cpu().view(-1, *size)\n",
        "    image_grid = make_grid(image_unflat[:num_images], nrow=5)\n",
        "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohhXQUMXkYFY"
      },
      "source": [
        "!wget https://www.dropbox.com/s/3vm9pavwc59i4cu/MNIST.zip\n",
        "!unzip MNIST.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZbqdw21hK5i"
      },
      "source": [
        "def get_noise(n_samples, z_dim, device='cpu'):\n",
        "    noise = torch.randn(n_samples,z_dim).to(device)\n",
        "    return noise\n",
        "\n",
        "def get_generator_block(input_dim, output_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(input_dim, output_dim),\n",
        "        nn.BatchNorm1d(output_dim),\n",
        "        nn.ReLU(inplace=True),\n",
        "    )\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim=10, im_dim=784, hidden_dim=128):\n",
        "        super(Generator, self).__init__()\n",
        "        self.gen = nn.Sequential(\n",
        "            get_generator_block(z_dim, hidden_dim),\n",
        "            get_generator_block(hidden_dim, hidden_dim * 2),\n",
        "            get_generator_block(hidden_dim * 2, hidden_dim * 4),\n",
        "            get_generator_block(hidden_dim * 4, hidden_dim * 8),\n",
        "            nn.Linear(hidden_dim * 8, im_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, noise):\n",
        "                return self.gen(noise)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYi8YFcseYFK"
      },
      "source": [
        "def get_discriminator_block(input_dim, output_dim):\n",
        "\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(input_dim, output_dim),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, im_dim=784, hidden_dim=128):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "            get_discriminator_block(im_dim, hidden_dim * 4),\n",
        "            get_discriminator_block(hidden_dim * 4, hidden_dim * 2),\n",
        "            get_discriminator_block(hidden_dim * 2, hidden_dim),\n",
        "            nn.Linear(hidden_dim,1)\n",
        "        )\n",
        "\n",
        "    def forward(self, image):\n",
        "           return self.disc(image)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFLQ039u-qdu"
      },
      "source": [
        "# Set your parameters\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "n_epochs = 200\n",
        "z_dim = 64\n",
        "display_step = 500\n",
        "batch_size = 128\n",
        "lr = 0.00001\n",
        "#device = 'cuda'\n",
        "device = 'cpu'\n",
        "# Load MNIST dataset as tensors\n",
        "dataloader = DataLoader(\n",
        "    MNIST('.', download=False, transform=transforms.ToTensor()),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDFRZ8tg_Y57"
      },
      "source": [
        "gen = Generator(z_dim).to(device)\n",
        "gen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\n",
        "disc = Discriminator().to(device)\n",
        "disc_opt = torch.optim.Adam(disc.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYzBtiYyz8IJ"
      },
      "source": [
        "def get_disc_loss(gen, disc, criterion, real, num_images, z_dim, device):\n",
        "\n",
        "    noise       = get_noise(num_images, z_dim, device)\n",
        "    fake_images = gen(noise)\n",
        "\n",
        "    fake_pred   = disc(fake_images.detach())\n",
        "    fake_true   = torch.zeros_like(fake_pred)\n",
        "    fake_loss   = criterion(fake_pred,fake_true)\n",
        "\n",
        "    real_pred   = disc(real)\n",
        "    real_true   = torch.ones_like(real_pred)\n",
        "    real_loss   = criterion(real_pred,real_true)\n",
        "\n",
        "    disc_loss   = (fake_loss+real_loss)/2\n",
        "\n",
        "    return disc_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV_8i6y30nTE"
      },
      "source": [
        "def get_gen_loss(gen, disc, criterion, num_images, z_dim, device):\n",
        "\n",
        "    noise       = get_noise(num_images, z_dim, device)\n",
        "    fake_images = gen(noise)\n",
        "\n",
        "    fake_pred   = disc(fake_images)\n",
        "\n",
        "    fake_true   = torch.ones_like(fake_pred)\n",
        "    gen_loss    = criterion(fake_pred,fake_true)\n",
        "\n",
        "    return gen_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXptQZcwrBrq"
      },
      "source": [
        "cur_step = 0\n",
        "mean_generator_loss = 0\n",
        "mean_discriminator_loss = 0\n",
        "test_generator = True\n",
        "gen_loss = False\n",
        "error = False\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "    for real, _ in tqdm(dataloader):\n",
        "        cur_batch_size = len(real)\n",
        "\n",
        "        real = real.view(cur_batch_size, -1).to(device)\n",
        "\n",
        "        disc_opt.zero_grad()\n",
        "\n",
        "        disc_loss = get_disc_loss(gen, disc, criterion, real, cur_batch_size, z_dim, device)\n",
        "\n",
        "        disc_loss.backward(retain_graph=True)\n",
        "\n",
        "        disc_opt.step()\n",
        "\n",
        "        if test_generator:\n",
        "            old_generator_weights = gen.gen[0][0].weight.detach().clone()\n",
        "\n",
        "\n",
        "        gen_opt.zero_grad()\n",
        "\n",
        "        gen_loss = get_gen_loss(gen, disc, criterion, cur_batch_size, z_dim, device)\n",
        "\n",
        "        gen_loss.backward(retain_graph=True)\n",
        "\n",
        "        gen_opt.step()\n",
        "\n",
        "        mean_discriminator_loss += disc_loss.item() / display_step\n",
        "\n",
        "        mean_generator_loss += gen_loss.item() / display_step\n",
        "\n",
        "        if cur_step % display_step == 0 and cur_step > 0:\n",
        "            print(f\"Step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n",
        "            fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
        "            fake = gen(fake_noise)\n",
        "            show_tensor_images(fake)\n",
        "            show_tensor_images(real)\n",
        "            mean_generator_loss = 0\n",
        "            mean_discriminator_loss = 0\n",
        "        cur_step += 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRciy40qSDQz"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}